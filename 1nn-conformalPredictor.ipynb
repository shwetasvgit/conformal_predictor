{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36f916a",
   "metadata": {},
   "source": [
    "<h3> CS3920/CS5920 Machine Learning Coursework</h3>\n",
    "\n",
    "<h4> Assignment 1</h4>\n",
    "    \n",
    "This Assignment contains implemention of the following :<br>\n",
    "- 1-Nearest Neighbor Classification Algorithm<br>\n",
    "- Conformal Predictor \n",
    "    \n",
    "This datasets are as follows:    \n",
    "            -Iris Dataset<br>\n",
    "            -Ionosphere Dataset<br>\n",
    "\n",
    "<h4> Table of Contents </h4>\n",
    "\n",
    "1. Exploring Datasets<br>\n",
    "2. 1-NN Implementation<br>\n",
    "3. Conformal Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099d251",
   "metadata": {},
   "source": [
    "<h2>1. Exploring Datasets </h2>\n",
    "<h3>1.1. Import Iris Dataset</h3>\n",
    "\n",
    "train_test_split() from Scikit Learn Package, splits the data into test and train sets.<br>This is done with a 75-25 ratio for train and test respectively.<br>\n",
    "random_state argument in test_train_split sets the seed to a specific state which helps to generate identical splits every time the function train_test_split() runs in order to have uniformity in every execution of the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd47be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(iris['data'],\n",
    "iris['target'], random_state=1403)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853da936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train set: (112, 4)\n",
      "Dimensions of test set: (112,)\n",
      "<class 'sklearn.utils.Bunch'>\n",
      "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train set:\",X_train_iris.shape)\n",
    "print(\"Dimensions of test set:\",y_train_iris.shape)\n",
    "print(type(iris))\n",
    "print(\"Features:\" ,iris.feature_names)\n",
    "print(\"Target:\", iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90d2a99",
   "metadata": {},
   "source": [
    "<h3>1.2 Import Ionosphere Dataset</h3>\n",
    "\n",
    "Function train_test_split() from Scikit Learn Package, splits the data into test and train sets.<br>This is done with a 75-25 ratio for train and test respectively.<br>\n",
    "random_state argument in test_train_split sets the seed to a specific state which helps to generate identical splits every time the function train_test_split() runs in order to uniformity in every execution of the code \n",
    "\n",
    "Note: Path for dataset file needs to be changed. A local dummy path has been provided "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "253ad341",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"E:\\RHUL\\Machine Learning\\LABS\\ionosphere.txt\", delimiter=\",\", usecols = np.arange(34))\n",
    "y = np.genfromtxt(\"E:\\RHUL\\Machine Learning\\LABS\\ionosphere.txt\", delimiter=\",\",dtype = int, usecols=34)\n",
    "X_train_ion, X_test_ion, y_train_ion, y_test_ion = train_test_split(X,\n",
    "y, random_state=1403)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89fe28fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train set: (263, 34)\n",
      "Dimensions of test set: (263,)\n",
      "Type of data: <class 'numpy.ndarray'>\n",
      "Null value in train set: False\n",
      "Null value in test set: False\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train set:\",X_train_ion.shape)\n",
    "print(\"Dimensions of test set:\",y_train_ion.shape)\n",
    "print(\"Type of data:\" ,type(X))\n",
    "from scipy import stats\n",
    "print(\"Null value in train set:\", np.isnan(X).all())\n",
    "print(\"Null value in test set:\", np.isnan(y).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43931434",
   "metadata": {},
   "source": [
    "<h3>2. 1-NN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189b3e7e",
   "metadata": {},
   "source": [
    "<h4>2.1 Function for Distance calculation</h4>\n",
    "    \n",
    "Here a function has been defined for calculating distance between 2-arrays. The input can be in form of list/tuple/set. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5be9d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(data_point_a,data_point_b):\n",
    "    \"\"\"\n",
    "    function description\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_point_a : Iterable list/tuple\n",
    "        This is a multi-dimensional point containing features of the data set. It can be train set/test set or any other\n",
    "    data_point_b : Iterable list/tuple\n",
    "        This is a multi-dimensional point containing features of the data set. It can be train set/test set or any other\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dist_sq : float\n",
    "    \n",
    "    \"\"\"\n",
    "    dist_sq = 0    \n",
    "    for i in range(len(data_point_b)):\n",
    "        dist_sq = dist_sq + (data_point_a[i]-data_point_b[i])**2     \n",
    "    return dist_sq**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9503d84",
   "metadata": {},
   "source": [
    "<h4>2.2 1-NN Function</h4>\n",
    "\n",
    "This function is for calculating the test error rate for 1 Nearest Neighbor. It can be used on any data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c06f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train,X_test,y_train,y_test):\n",
    "    \"\"\"\n",
    "    This function is used to calculate the 1-NN. It calculates the minimum distance using the helper function dist().\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : numpy array\n",
    "        Train set of features \n",
    "    X_test : numpy array\n",
    "        Test set of features\n",
    "    y_train : numpy array\n",
    "        Train set of labels\n",
    "    y_test : numpy array\n",
    "        Test set of labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TYPE : test error rate , count false values\n",
    "        \n",
    "    \"\"\"\n",
    "    y_pred = []\n",
    "    count = 0\n",
    "    #iterate through test sample and train sample for closest neighbour\n",
    "    for test_sample in X_test:\n",
    "        min_dist = np.inf\n",
    "        for train_sample in range(len(X_train)):\n",
    "            current_dist = dist(list(test_sample),list(X_train[train_sample]))                      \n",
    "            if current_dist < min_dist :                \n",
    "                min_dist = current_dist\n",
    "                result = train_sample               \n",
    "        y_pred.append(y_train[result])\n",
    "    #count false predictions\n",
    "    for label in range(len(y_pred)):\n",
    "        if y_pred[label] !=y_test[label]:\n",
    "            count = count + 1       \n",
    "    return np.mean(y_pred!=y_test),count         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c0cc9",
   "metadata": {},
   "source": [
    "<h4>2.3 1-NN for Ionosphere</h4>\n",
    "Function call for 1-NN for Ionosphere Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab8d021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate : 0.10227272727272728\n",
      "Accuracy: 89.77272727272727\n",
      "Number of errors: 9\n"
     ]
    }
   ],
   "source": [
    "test_error_rate_ion, mismatch_count_ion = knn( X_train_ion,X_test_ion, y_train_ion, y_test_ion)\n",
    "print(\"Test error rate :\",test_error_rate_ion)\n",
    "print(\"Accuracy:\", (1-test_error_rate_ion)*100)\n",
    "print(\"Number of errors:\",mismatch_count_ion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c65ed1",
   "metadata": {},
   "source": [
    "<h4>2.4 1-NN for IRIS</h4>\n",
    "Function call for 1-NN for Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de404c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error rate : 0.02631578947368421\n",
      "Accuracy: 97.36842105263158\n",
      "Number of errors: 1\n"
     ]
    }
   ],
   "source": [
    "test_error_rate_iris,mismatch_count_iris = knn(X_train_iris,X_test_iris, y_train_iris, y_test_iris)\n",
    "print(\"Test error rate :\",test_error_rate_iris)\n",
    "print(\"Accuracy:\", (1-test_error_rate_iris)*100)\n",
    "print(\"Number of errors:\",mismatch_count_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1896920",
   "metadata": {},
   "source": [
    "<h3> 3. Conformal Prediction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "078acbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conformal_pred(X_train,X_test,y_train,y_test):   \n",
    "    \"\"\"\n",
    "    This function implements the conformal predictor for dataset passed in the arguments.\n",
    "    Following are the steps involved :\n",
    "    1) Assume label for test set to be one among the unique train label set values\n",
    "    2) Create extended training dataset: Add the assumed test set to the training set.\n",
    "    3) For each element in the extended training dataset, calculate minimum same class distance , \n",
    "    minimum different class distance and update these values as you iterate through the set to find minimum\n",
    "    4) Calculate the conformity score using c = minimum different class distance /minimum same class distance and store them\n",
    "    5) Rank the above score by sorting and calculate the p values for each assumed label for each test label, create matrix\n",
    "    6) From m*n matrix (m = number of test_label , n = number of unique labels), compare true labels from initial test data \n",
    "    and find the average false p-values \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : numpy array\n",
    "        Train set of features \n",
    "    X_test : numpy array\n",
    "        Test set of features\n",
    "    y_train : numpy array\n",
    "        Train set of labels\n",
    "    y_test : numpy array\n",
    "        Test set of labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TYPE : float, List\n",
    "    Average false p value , matrix for p-values\n",
    "        \n",
    "    \"\"\"\n",
    "    p_value_false = []\n",
    "    p_avg_false = []\n",
    "    #loop to iterate over the test samples\n",
    "    for test_sample in range(len(X_test)):  \n",
    "        p_value_false.append([])\n",
    "        rank = {}    \n",
    "        #Loop to iterate over the number of unique labels in the data\n",
    "        for i in range(len(set(y_test))):        \n",
    "            conformity_score = []\n",
    "            X_combined = np.append(X_train,[X_test[test_sample]],axis=0)\n",
    "            y_combined = np.append(y_train,[np.unique(y_test)[i]],axis=0) \n",
    "            #Loop to iterate over extended train-set\n",
    "            for train_sample in range(len(X_combined)):\n",
    "                min_same_dist = np.inf\n",
    "                min_diff_dist = np.inf\n",
    "                #Loop to compare each element of extended train set and calculate min same/diff distance \n",
    "                for dist_element in range(len(X_combined)):                \n",
    "                    if dist_element != train_sample:                   \n",
    "                        if y_combined[dist_element] == y_combined[train_sample] :  \n",
    "                            current_same_dist = dist(list(X_combined[dist_element]),list(X_combined[train_sample]))\n",
    "                            if current_same_dist < min_same_dist:\n",
    "                                min_same_dist = current_same_dist     \n",
    "                        else:\n",
    "                            current_diff_dist = dist(list(X_combined[dist_element]),list(X_combined[train_sample]))\n",
    "                            if current_diff_dist < min_diff_dist:\n",
    "                                min_diff_dist = current_diff_dist\n",
    "                #calculation of confirmity score for each sample in the extended train set and saving it in a list                \n",
    "                conformity_score.append({'index': train_sample, 'distance': min_diff_dist/min_same_dist})\n",
    "            #sort the final conformity score to find out the ranks\n",
    "            conformity_score = sorted(conformity_score,key = lambda i: i['distance'])\n",
    "            #Find all p values and store in a matrix (list)\n",
    "            p_val = (conformity_score.index(next(item for item in conformity_score if item[\"index\"]==(len(X_combined))-1))+1)/len(X_combined)\n",
    "            #store p values\n",
    "            p_value_false[test_sample].append(p_val)\n",
    "\n",
    "    #Average false p_value calculation         \n",
    "    for test_label in range(len(y_test)):\n",
    "        for i in range(len(set(y_test))):\n",
    "                if np.unique(y_test)[i] != y_test[test_label]:\n",
    "                    p_avg_false.append(p_value_false[test_label][i])                                          \n",
    "    p_avg_false_values = sum(p_avg_false)/len(p_avg_false) \n",
    "    return p_avg_false_values, p_value_false   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba57c2",
   "metadata": {},
   "source": [
    "<h4>3.1 Conformal Predictor for IRIS data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af84d669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average false p_values  0.010013972985561259\n",
      "p_value matrix:\n",
      "[[0.008849557522123894, 0.008849557522123894, 0.5486725663716814], [0.6637168141592921, 0.008849557522123894, 0.008849557522123894], [0.831858407079646, 0.008849557522123894, 0.008849557522123894], [0.672566371681416, 0.008849557522123894, 0.008849557522123894], [0.008849557522123894, 0.008849557522123894, 0.13274336283185842], [0.008849557522123894, 0.008849557522123894, 0.4336283185840708], [0.008849557522123894, 0.39823008849557523, 0.008849557522123894], [0.008849557522123894, 0.008849557522123894, 0.24778761061946902], [0.008849557522123894, 0.008849557522123894, 0.3805309734513274], [0.008849557522123894, 0.008849557522123894, 0.5132743362831859], [0.008849557522123894, 0.008849557522123894, 0.30973451327433627], [0.008849557522123894, 0.008849557522123894, 0.4336283185840708], [0.008849557522123894, 0.008849557522123894, 0.24778761061946902], [0.831858407079646, 0.008849557522123894, 0.008849557522123894], [0.008849557522123894, 0.008849557522123894, 0.3185840707964602], [0.008849557522123894, 0.008849557522123894, 0.168141592920354], [0.9734513274336283, 0.008849557522123894, 0.008849557522123894], [0.008849557522123894, 0.504424778761062, 0.008849557522123894], [0.008849557522123894, 0.8053097345132744, 0.008849557522123894], [0.008849557522123894, 0.008849557522123894, 0.5221238938053098], [0.831858407079646, 0.008849557522123894, 0.008849557522123894], [0.008849557522123894, 0.008849557522123894, 0.26548672566371684], [0.008849557522123894, 0.25663716814159293, 0.008849557522123894], [0.008849557522123894, 0.3274336283185841, 0.008849557522123894], [0.7345132743362832, 0.008849557522123894, 0.008849557522123894], [0.008849557522123894, 0.008849557522123894, 0.2920353982300885], [0.008849557522123894, 0.008849557522123894, 0.3185840707964602], [0.008849557522123894, 0.008849557522123894, 0.7079646017699115], [0.008849557522123894, 0.017699115044247787, 0.13274336283185842], [0.6991150442477876, 0.008849557522123894, 0.008849557522123894], [0.008849557522123894, 0.6991150442477876, 0.008849557522123894], [0.008849557522123894, 0.008849557522123894, 0.20353982300884957], [0.008849557522123894, 0.008849557522123894, 0.4247787610619469], [0.008849557522123894, 0.008849557522123894, 0.3274336283185841], [0.008849557522123894, 0.02654867256637168, 0.08849557522123894], [0.9557522123893806, 0.008849557522123894, 0.008849557522123894], [0.6902654867256637, 0.008849557522123894, 0.008849557522123894], [0.008849557522123894, 0.008849557522123894, 0.40707964601769914]]\n"
     ]
    }
   ],
   "source": [
    "avg_value, p_val_matrix = conformal_pred(X_train_iris,X_test_iris,y_train_iris,y_test_iris)\n",
    "print(\"The average false p_values \", avg_value)\n",
    "print(\"p_value matrix:\")\n",
    "print(p_val_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64606f82",
   "metadata": {},
   "source": [
    "<h4>3.2 Conformal Predictor for Ionosphere dataset</h4>\n",
    "Note : Ionosphere data is heavy for the conformal predictor for random state 1403 and takes more time than iris dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7b7a039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average false p_value : 0.05259986225895323\n",
      "p_value matrix:\n",
      "[[0.003787878787878788, 0.9128787878787878], [0.003787878787878788, 0.9128787878787878], [0.553030303030303, 0.011363636363636364], [0.003787878787878788, 0.7348484848484849], [0.4696969696969697, 0.015151515151515152], [0.3484848484848485, 0.06439393939393939], [0.003787878787878788, 0.7651515151515151], [0.003787878787878788, 0.9772727272727273], [0.007575757575757576, 0.6401515151515151], [0.2803030303030303, 0.0946969696969697], [0.015151515151515152, 0.4583333333333333], [0.003787878787878788, 0.7727272727272727], [0.2878787878787879, 0.09090909090909091], [0.003787878787878788, 0.8977272727272727], [0.003787878787878788, 0.7651515151515151], [0.125, 0.1590909090909091], [0.20454545454545456, 0.10984848484848485], [0.3333333333333333, 0.06439393939393939], [0.011363636363636364, 0.48863636363636365], [0.011363636363636364, 0.6287878787878788], [0.003787878787878788, 0.9772727272727273], [0.125, 0.16287878787878787], [0.24242424242424243, 0.09848484848484848], [0.003787878787878788, 0.9734848484848485], [0.003787878787878788, 0.7689393939393939], [0.003787878787878788, 0.7386363636363636], [0.3560606060606061, 0.05303030303030303], [0.003787878787878788, 0.9659090909090909], [0.003787878787878788, 0.9621212121212122], [0.3484848484848485, 0.06060606060606061], [0.003787878787878788, 0.7007575757575758], [0.003787878787878788, 0.8863636363636364], [0.5075757575757576, 0.011363636363636364], [0.003787878787878788, 0.9734848484848485], [0.3371212121212121, 0.06439393939393939], [0.36742424242424243, 0.05303030303030303], [0.003787878787878788, 0.7045454545454546], [0.003787878787878788, 0.803030303030303], [0.007575757575757576, 0.5871212121212122], [0.3409090909090909, 0.06439393939393939], [0.003787878787878788, 0.9166666666666666], [0.003787878787878788, 0.9128787878787878], [0.022727272727272728, 0.4318181818181818], [0.03787878787878788, 0.39015151515151514], [0.0946969696969697, 0.26515151515151514], [0.003787878787878788, 0.9128787878787878], [0.003787878787878788, 0.9090909090909091], [0.007575757575757576, 0.5189393939393939], [0.003787878787878788, 0.7727272727272727], [0.003787878787878788, 0.7310606060606061], [0.38636363636363635, 0.041666666666666664], [0.553030303030303, 0.011363636363636364], [0.011363636363636364, 0.5075757575757576], [0.003787878787878788, 0.8787878787878788], [0.003787878787878788, 0.9015151515151515], [0.003787878787878788, 0.821969696969697], [0.007575757575757576, 0.6515151515151515], [0.17803030303030304, 0.11742424242424243], [0.007575757575757576, 0.553030303030303], [0.19696969696969696, 0.10984848484848485], [0.003787878787878788, 0.8787878787878788], [0.003787878787878788, 0.7727272727272727], [0.2840909090909091, 0.09090909090909091], [0.011363636363636364, 0.5871212121212122], [0.09848484848484848, 0.23863636363636365], [0.003787878787878788, 0.9204545454545454], [0.011363636363636364, 0.5568181818181818], [0.5492424242424242, 0.007575757575757576], [0.36363636363636365, 0.05303030303030303], [0.003787878787878788, 0.7727272727272727], [0.007575757575757576, 0.678030303030303], [0.003787878787878788, 0.8863636363636364], [0.007575757575757576, 0.5265151515151515], [0.003787878787878788, 0.7916666666666666], [0.3522727272727273, 0.06060606060606061], [0.003787878787878788, 0.7121212121212122], [0.2803030303030303, 0.09090909090909091], [0.003787878787878788, 0.8901515151515151], [0.125, 0.1590909090909091], [0.007575757575757576, 0.6477272727272727], [0.003787878787878788, 0.7045454545454546], [0.011363636363636364, 0.4659090909090909], [0.3712121212121212, 0.04924242424242424], [0.007575757575757576, 0.6477272727272727], [0.022727272727272728, 0.45075757575757575], [0.2878787878787879, 0.0946969696969697], [0.4015151515151515, 0.041666666666666664], [0.2765151515151515, 0.0946969696969697]]\n"
     ]
    }
   ],
   "source": [
    "avg_value_ion, p_val_matrix_ion = conformal_pred(X_train_ion,X_test_ion,y_train_ion,y_test_ion)\n",
    "print(\"The average false p_value :\", avg_value_ion)\n",
    "print(\"p_value matrix:\")\n",
    "print(p_val_matrix_ion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
